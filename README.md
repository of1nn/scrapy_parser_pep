# scrapy_parser_pep

## Описание
Этот проект представляет собой парсер PEP (Python Enhancement Proposals), который использует фреймворк Scrapy для извлечения информации о PEP с официального сайта Python. Парсер собирает данные о номере PEP, его названии и статусе, а затем сохраняет их в структурированном формате.

## Установка
Для работы с парсером необходимо установить следующие зависимости:

```pip install scrapy```
Использование
Чтобы запустить парсер, выполните следующую команду в терминале:

```scrapy crawl pep```
Структура проекта
- pep_parse/
- items.py - определения моделей данных для PEP.
- pipelines.py - обработка и сохранение данных после парсинга.
- settings.py - настройки проекта Scrapy.
- spiders/
- pep_spider.py - основной код парсера.
## Работа парсера
Парсер начинает свою работу с главной страницы PEP, извлекает ссылки на все PEP и последовательно переходит по ним для сбора данных. Информация о каждом PEP сохраняется в виде объекта PepParseItem.

## Обработка данных
После извлечения данных они передаются в PepParsePipeline, где подсчитывается количество PEP по статусам. По завершении работы парсера результаты сохраняются в CSV-файл.